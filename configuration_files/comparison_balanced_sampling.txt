# to edit: do an evaluation every {eval_interval} iterations
eval_interval = 3000
eval_iters = 1
always_save_checkpoint = True


wandb_log = True # override via command line if you like
wandb_project = 'addition'

# to edit: wandb run name
wandb_run_name = 'comparison'

# baby GPT model :)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

# to edit: 'plain' or 'reverse' or 'algo_reasoning'
data_format='plain'
operator=','
dataset = 'bal'
batch_size = 512
block_size = 16 # context of up to 256 previous characters

# to edit: 'scratch' or 'resume', whether train from scratch or resume from a saved checkpoint
init_from = 'scratch'
iter_num = 0
# to edit: the checkpoint from which to resume training
ckpt_path_name = 'ckpt_iter_19000_acc.pt'

# to edit: whether the result is reversed
reverse_c = False
eval_addition = True

analysis = False

# to edit: num of digits in each operand
num_digit = 4

# to edit: maximum number of output tokens (including '$')
max_new_tokens = 2

drop_leading_digit = False

# whether need zero‚Äêpadding
zero_pad = False

# ===== Learning Rate Policy ===== #
learning_rate = 1e-3

# to edit: the number of training iterations
max_iters = 50000
lr_decay_iters = 50000 # make equal to max_iters usually (300000)

beta1 = 0.9
beta2 = 0.98
warmup_iters = 100

# ===== Device ===== #
device='cuda:0'

# to edit: the output directory
out_dir = '/content/drive/MyDrive/comparison/result'

# to edit: training data
train_data_path = '/content/drive/MyDrive/comparison/data/train_balanced_sampling.txt'

# to edit: whether do evaluation on training data to see if the model is simply memorizing
eval_addition_train = True
train_data_test_path = "/content/drive/MyDrive/comparison/data/train_tests.txt"

# to edit: validation data
val_data_path = '/content/drive/MyDrive/comparison/data/val.txt'

# to edit: test data; start is just the test file. It can be either without gold (thus gold by computing) or with gold (thus gold by reading)
test_file_path = '/content/drive/MyDrive/comparison/data/test/test_balanced_sampling.txt'

# to edit: "compute_gold" or "read_gold_as_str"; read or compute groundtruth in evaluation data
mode = "read_gold_as_str"

# to edit: whether to do more frequenly evaluations in early stages
early_eval_interval1 = 50
early_eval_border1 = 500

more_early_eval2 = True
early_eval_interval2 = 500
early_eval_border2 = 5000



more_early_eval1=True

eval_additional_test = True
test_dir = '/content/drive/MyDrive/comparison/data/test'
